{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "9ea552dc-2ab8-a0ac-dda5-dd7c385a1d3a"
   },
   "source": [
    "# Introduction\n",
    "Here we process the data from the electron microscopy 3D dataset, the first lines automatically download it if you have Kaggle setup otherwise you can download the dataset [here](https://www.epfl.ch/labs/cvlab/data/data-em/). The download link might be slow, in that case please log into Kaggle and download the data from here: https://www.kaggle.com/kmader/electron-microscopy-3d-segmentation\n",
    "\n",
    "You need:\n",
    "- Training sub volume\n",
    "- Ground truth sub volume\n",
    "\n",
    "Save the images in the sub folder \"input\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "if not os.path.exists('input'):\n",
    "    !curl -L -o input/electron-microscopy-3d-segmentation.zip https://www.kaggle.com/api/v1/datasets/download/kmader/electron-microscopy-3d-segmentation\n",
    "    !unzip input/electron-microscopy-3d-segmentation.zip -d input\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f7ca9567-9c3e-f6a9-075c-216307025533"
   },
   "outputs": [],
   "source": [
    "import matplotlib.patches as mpatches  # for showing rectangles and annotations\n",
    "from skimage.color import label2rgb  # for making overlay plots\n",
    "import numpy as np  # for matrix operations and array support\n",
    "from skimage.measure import regionprops  # for shape analysis\n",
    "from skimage.measure import label  # for labeling regions\n",
    "import matplotlib.pyplot as plt  # for showing plots\n",
    "from skimage.io import imread  # for reading images\n",
    "from scipy import ndimage\n",
    "from skimage.morphology import medial_axis\n",
    "from skimage.segmentation import watershed\n",
    "create_dist_map = lambda img, mask=None: medial_axis(img,mask, return_distance = True)[1]\n",
    "plt_settings = {'interpolation':'none'}\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ffbd3d02-e49a-23e9-7789-b91f88cff3cf"
   },
   "source": [
    "# Connected Component Labeling\n",
    "scikit-image has basic support for [connected component labeling](http://scikit-image.org/docs/dev/api/skimage.measure.html#skimage.measure.label) and we can do some small demos with the label function and small test images, before moving onto bigger datasets. \n",
    "\n",
    "## Neighborhood\n",
    "In the course we use the term neighborhood and here we use the term ```connectivity``` for the same idea. \n",
    "\n",
    " - For a 2D image a connectivity = 1 is just the 4-neighborhood (or pixels that share an edge, connectivity = 2 is then 8-neighborhood (or pixels that share a vertex)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bc5c886a-18a9-3abf-7b51-ea8df86530af"
   },
   "outputs": [],
   "source": [
    "# simple test image diagonal\n",
    "test_img = np.eye(4)\n",
    "print('Input Image')\n",
    "print(test_img)\n",
    "\n",
    "test_label_4 = label(test_img, connectivity=1)\n",
    "print('Labels with 4-neighborhood')\n",
    "print(test_label_4)\n",
    "\n",
    "test_label_8 = label(test_img, connectivity=2)\n",
    "print('Labels with 8-neighborhood')\n",
    "print(test_label_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the images\n",
    "fig, ax = plt.subplots(1, 3, figsize=(12, 6))\n",
    "im1 = ax[0].imshow(test_img.astype(int), cmap='gray')\n",
    "ax[0].set_title('Input Image')\n",
    "im2 = ax[1].imshow(test_label_4, cmap='nipy_spectral')\n",
    "ax[1].set_title('Labels with 4-neighborhood')\n",
    "im3 = ax[2].imshow(test_label_8, cmap='nipy_spectral')\n",
    "ax[2].set_title('Labels with 8-neighborhood')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "ca54e2df-8d90-3ef8-2f96-dd7d1ba4ab1a"
   },
   "source": [
    "## 3D Neighborhood\n",
    "\n",
    "For a 3D image a connectivity = 1 is just the 6-neighborhood (or voxels that share an face, connectivity = 2 is then voxels that share an edge and 3 is voxels that share a vertex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "a49571af-5e81-6c7f-6354-336e4968b0ac"
   },
   "outputs": [],
   "source": [
    "test_img = np.array(\n",
    "    [1 if x in [0, 13, 26] else 0 for x in range(27)]).reshape((3, 3, 3))\n",
    "print('Input Image')\n",
    "print(test_img)\n",
    "\n",
    "test_label_1 = label(test_img, connectivity=1)\n",
    "print('Labels with Face-sharing')\n",
    "print(test_label_1)\n",
    "\n",
    "test_label_2 = label(test_img, connectivity=2)\n",
    "print('Labels with Edge-Sharing')\n",
    "print(test_label_2)\n",
    "\n",
    "test_label_3 = label(test_img, connectivity=3)\n",
    "print('Labels with Vertex-Sharing')\n",
    "print(test_label_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the 3 volumes in 3D\n",
    "fig = plt.figure(figsize=(12, 6))\n",
    "ax1 = fig.add_subplot(131, projection='3d')\n",
    "ax2 = fig.add_subplot(132, projection='3d')\n",
    "ax3 = fig.add_subplot(133, projection='3d')\n",
    "\n",
    "# Function to generate colors based on voxel values\n",
    "def generate_colors(volume):\n",
    "    colors = np.empty(volume.shape, dtype=object)\n",
    "    for i in range(volume.shape[0]):\n",
    "        for j in range(volume.shape[1]):\n",
    "            for k in range(volume.shape[2]):\n",
    "                value = volume[i, j, k]\n",
    "                if value == 0:\n",
    "                    colors[i, j, k] = 'white'\n",
    "                elif value == 1:\n",
    "                    colors[i, j, k] = 'blue'\n",
    "                elif value == 2:\n",
    "                    colors[i, j, k] = 'green'\n",
    "                elif value == 3:\n",
    "                    colors[i, j, k] = 'red'\n",
    "                # Add more conditions for other values if needed\n",
    "    return colors\n",
    "\n",
    "# Plot the 3D volumes with different colors for each voxel\n",
    "colors1 = generate_colors(test_label_1)\n",
    "colors2 = generate_colors(test_label_2)\n",
    "colors3 = generate_colors(test_label_3)\n",
    "\n",
    "ax1.voxels(test_label_1, edgecolor='k', facecolors=colors1)\n",
    "ax1.set_title('Face-sharing')\n",
    "ax2.voxels(test_label_2, edgecolor='k', facecolors=colors2)\n",
    "ax2.set_title('Edge-sharing')\n",
    "ax3.voxels(test_label_3, edgecolor='k', facecolors=colors3)\n",
    "ax3.set_title('Vertex-sharing')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "bca1bf58-37f9-db1f-4444-8960a7d4b0cd"
   },
   "outputs": [],
   "source": [
    "def imread_or_invent(in_path):\n",
    "    np.random.seed(2018)\n",
    "    if os.path.exists(in_path):\n",
    "        return imread(in_path)\n",
    "    else:\n",
    "        print('Getting creative...')\n",
    "        fake_shape = (10, 50, 75)\n",
    "        if 'groundtruth' in in_path:\n",
    "            return (np.random.uniform(0, 1, size=fake_shape) > 0.99).astype(int)\n",
    "        else:\n",
    "            return np.random.uniform(0, 1, size=fake_shape)\n",
    "\n",
    "\n",
    "em_image_vol = imread_or_invent('input/training.tif')\n",
    "em_thresh_vol = imread_or_invent('input/training_groundtruth.tif')\n",
    "print(\"Data Loaded, Dimensions\", em_image_vol.shape, '->', em_thresh_vol.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "160081b9-ab62-e268-50f5-6d34053f79d8"
   },
   "source": [
    "# 2D Analysis\n",
    "Here we work with a single 2D slice to get started and take it randomly from the middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "be4e88a3-8b8c-9fa0-acd9-8297b8e282df"
   },
   "outputs": [],
   "source": [
    "em_idx = np.random.permutation(range(em_image_vol.shape[0]))[0]\n",
    "em_slice = em_image_vol[em_idx]\n",
    "em_thresh = em_thresh_vol[em_idx]\n",
    "print(\"Slice Loaded, Dimensions\", em_slice.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "d3fe48c8-ebb3-af65-777a-c8d638946072"
   },
   "outputs": [],
   "source": [
    "# show the slice and threshold\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(9, 4))\n",
    "ax1.imshow(em_slice, cmap='gray')\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Image')\n",
    "ax2.imshow(em_thresh, cmap='gray')\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Segmentation')\n",
    "# here we mark the threshold on the original image\n",
    "\n",
    "ax3.imshow(label2rgb(em_thresh, em_slice, bg_label=0))\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Overlayed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "574c1696-a1fc-2267-db34-ec0b4b310672"
   },
   "outputs": [],
   "source": [
    "# make connected component labels\n",
    "em_label = label(em_thresh)\n",
    "print(em_label.max(), 'number of labels')\n",
    "# show the segmentation, labels and overlay\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(9, 4))\n",
    "ax1.imshow(em_thresh, cmap='gray')\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Segmentation')\n",
    "ax2.imshow(em_label, cmap=plt.cm.gist_earth)\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Labeling')\n",
    "# here we mark the threshold on the original image\n",
    "\n",
    "ax3.imshow(label2rgb(em_label, em_slice, bg_label=0))\n",
    "ax3.axis('off')\n",
    "ax3.set_title('Overlayed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "cfabd782-de43-ea00-856a-b0cbb755ca1a"
   },
   "source": [
    "# Shape Analysis \n",
    "For shape analysis we use the regionprops function which calculates the area, perimeter, and other features for a shape. The analysis creates a list of these with one for each label in the original image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "f924cdaf-2d55-5089-51b9-8aa6ec820a3b"
   },
   "outputs": [],
   "source": [
    "shape_analysis_list = regionprops(em_label)\n",
    "first_region = shape_analysis_list[0]\n",
    "print('List of region properties for', len(shape_analysis_list), 'regions')\n",
    "print('Features Calculated:', ', '.join(\n",
    "    [f for f in dir(first_region) if not f.startswith('_')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "5cc2bacc-26d5-e55a-8e64-caadaf3010d8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(label2rgb(em_label, em_slice, bg_label=0))\n",
    "\n",
    "for region in shape_analysis_list:\n",
    "    # draw rectangle using the bounding box\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                              fill=False, edgecolor='red', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4b59cd5a-2c6f-75eb-a90a-993dd484d1be"
   },
   "source": [
    "## Anisotropy\n",
    "We can calculate anisotropy as we did in the course by using the largest and shortest lengths, called here as ```major_axis_length``` and ```minor_axis_length``` respectively\n",
    "\n",
    "- Try using different formulas for anisotropy to see how it changes what is shown\n",
    "\n",
    "$$ Aiso1 = \\frac{\\text{Longest Side}}{\\text{Shortest Side}} - 1 $$\n",
    "\n",
    "$$ Aiso2 = \\frac{\\text{Longest Side}-\\text{Shortest Side}}{\\text{Longest Side}} $$\n",
    "\n",
    "$$ Aiso3 = \\frac{\\text{Longest Side}}{\\text{Average Side Length}} - 1 $$\n",
    "\n",
    "$$ Aiso4 = \\frac{\\text{Longest Side}-\\text{Shortest Side}}{\\text{Average Side Length}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "3954c870-771c-7c9a-ca4b-6ed302ff5d67"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "ax.imshow(label2rgb(em_label, em_slice, bg_label=0))\n",
    "\n",
    "for region in shape_analysis_list:\n",
    "    x1 = region.major_axis_length\n",
    "    x2 = region.minor_axis_length\n",
    "    anisotropy = x1/x2 -1 if x2 > 0 else 0\n",
    "    # anisotropy = (x1-x2)/np.clip((x1+x2)/2, 0.1, 9999)\n",
    "    # for anisotropic shapes use red for the others use blue\n",
    "    print('Label:', region.label, 'Anisotropy %2.2f' % anisotropy)\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    rect = mpatches.Rectangle((minc, minr), maxc - minc, maxr - minr,\n",
    "                                fill=False, edgecolor='red' if anisotropy > 0.3 else 'green', linewidth=2)\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "ax.set_axis_off()\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distance Maps\n",
    "Here we calculate distance maps with the ```ndimage.distance_transform_``` family of functions. Initially we focus on test images since it is easier to see what is happening with these images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dot_image(size = 100, cutoff = 0.15):\n",
    "    \"\"\"\n",
    "    Create a simple  synthetic image with a repeating pattern\n",
    "    Keyword arguments:\n",
    "    size -- the size of the image on one size, final size is size x size (default 100)\n",
    "    imag -- the cutoff between 0 and 1, higher means less connected objects (default 0.15)\n",
    "    \"\"\"\n",
    "    xx,yy = np.meshgrid(range(size),range(size))\n",
    "    return np.sin(6*np.pi*xx/(100)-1)+1.25*np.cos(5*np.pi*yy/(100)-2)>cutoff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "img_bw = generate_dot_image(28,0.50)\n",
    "plt.imshow(img_bw,cmap='gray', **plt_settings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "img_dist = ndimage.distance_transform_edt(img_bw)\n",
    "plt.imshow(img_dist, **plt_settings)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing \n",
    "There are a number of different methods for ```distance_transform``` inside the ```ndimage``` package of ```scipy``` compare the results of the different approaches for this and other images.\n",
    "- What are the main differences?\n",
    "- Quantitatively (histogram) show what situations each one might be best suited for?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# calculate new distance transforms\n",
    "img_dist = ndimage.distance_transform_edt(img_bw)\n",
    "img_dist_cityblock = ndimage.distance_transform_cdt(img_bw,metric = 'taxicab')\n",
    "img_dist_chess = ndimage.distance_transform_cdt(img_bw,metric = 'chessboard')\n",
    "\n",
    "fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4, figsize = (30,10))\n",
    "ax1.imshow(img_bw,cmap = 'gray', **plt_settings)\n",
    "ax1.set_title('Mask Image')\n",
    "dmap_im = ax2.imshow(img_dist,vmax = img_dist.max(), **plt_settings)\n",
    "ax2.set_title('Euclidean')\n",
    "ax3.imshow(img_dist_cityblock,vmax = img_dist.max(), **plt_settings)\n",
    "ax3.set_title('Cityblock')\n",
    "ax4.imshow(img_dist_chess,vmax = img_dist.max(), **plt_settings)\n",
    "ax4.set_title('Chess')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "cbar = fig.colorbar(dmap_im,cax=cbar_ax)\n",
    "cbar_ax.set_title('Distance\\n(px)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Euclidean Distance Transform (EDT)**\n",
    "$$\n",
    "d_E(p) = \\min_{q \\in S} \\| p - q \\|_2\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "\\| p - q \\|_2 = \\sqrt{(x_p - x_q)^2 + (y_p - y_q)^2}\n",
    "$$\n",
    "\n",
    "2. **City Block (Manhattan) Distance Transform (CDT, Taxicab metric)**\n",
    "$$\n",
    "d_{M}(p) = \\min_{q \\in S} \\| p - q \\|_1\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "\\| p - q \\|_1 = |x_p - x_q| + |y_p - y_q|\n",
    "$$\n",
    "\n",
    "3. **Chessboard Distance Transform (CDT, Chessboard metric)**\n",
    "$$\n",
    "d_C(p) = \\min_{q \\in S} \\| p - q \\|_{\\infty}\n",
    "$$\n",
    "where:\n",
    "$$\n",
    "\\| p - q \\|_{\\infty} = \\max(|x_p - x_q|, |y_p - y_q|)\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Complicated Objects\n",
    "We now make the image bigger (changing the ```size``` parameter) and connect them together (the ```cutoff``` parameter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "# use a bigger base image\n",
    "img_bw = generate_dot_image(100,0.15)\n",
    "img_dist = ndimage.distance_transform_edt(img_bw)\n",
    "img_dist_cityblock = ndimage.distance_transform_cdt(img_bw,metric = 'taxicab')\n",
    "img_dist_chess = ndimage.distance_transform_cdt(img_bw,metric = 'chessboard')\n",
    "\n",
    "fig, (ax1,ax2,ax3,ax4) = plt.subplots(1,4, figsize = (30,10))\n",
    "ax1.imshow(img_bw,cmap = 'gray', **plt_settings)\n",
    "ax1.set_title('Mask Image')\n",
    "dmap_im = ax2.imshow(img_dist,vmax = img_dist.max(), **plt_settings)\n",
    "ax2.set_title('Euclidean')\n",
    "ax3.imshow(img_dist_cityblock,vmax = img_dist.max(), **plt_settings)\n",
    "ax3.set_title('Cityblock')\n",
    "ax4.imshow(img_dist_chess,vmax = img_dist.max(), **plt_settings)\n",
    "ax4.set_title('Chess')\n",
    "fig.subplots_adjust(right=0.8)\n",
    "cbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\n",
    "cbar = fig.colorbar(dmap_im,cax=cbar_ax)\n",
    "cbar_ax.set_title('Distance\\n(px)')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Watershed\n",
    "We can use the watershed transform to segment closely connected objects. We see in the first image that the standard connected component labeling ```ndimage.label``` shows only 3 when we see 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc_img = ndimage.label(img_bw)[0]\n",
    "\n",
    "%matplotlib inline\n",
    "fig, (ax1,ax2) = plt.subplots(1,2, figsize = (30,10))\n",
    "ax1.imshow(img_bw,cmap = 'gray', **plt_settings)\n",
    "ax1.set_title('Mask Image')\n",
    "dmap_im = ax2.imshow(cc_img, **plt_settings)\n",
    "ax2.set_title('Connected Component Analysis');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import peak_local_max\n",
    "def simple_watershed(img_dist, img_bw):\n",
    "    \"\"\"\n",
    "    Calculate the watershed transform on an image and its distance map \n",
    "    by finding the troughs and expanding from these points.\n",
    "    \"\"\"\n",
    "    # Find local maxima\n",
    "    local_maxi_coords = peak_local_max(img_dist, labels=img_bw, footprint=np.ones((9, 9)))\n",
    "\n",
    "    # Create image from the local maxima\n",
    "    local_maxi = np.zeros(img_dist.shape, dtype=bool)\n",
    "    local_maxi[local_maxi_coords[:, 0], local_maxi_coords[:, 1]] = True\n",
    "\n",
    "    # Label the maxima\n",
    "    markers = ndimage.label(local_maxi)[0]\n",
    "\n",
    "    return watershed(-img_dist, markers, mask=img_bw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying Watershed\n",
    "We can apply watershed to the following image. \n",
    "- Why do the bottom row of objects not show up?\n",
    "- How can the results be improved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws_img = simple_watershed(img_dist,img_bw)\n",
    "%matplotlib inline\n",
    "fig, (ax1,ax2,ax3) = plt.subplots(1,3, figsize = (30,10))\n",
    "ax1.imshow(img_bw,cmap = 'gray', **plt_settings)\n",
    "ax1.set_title('Mask Image')\n",
    "ax2.imshow(cc_img, cmap=\"tab20\",**plt_settings)\n",
    "ax2.set_title('Connected Component Analysis')\n",
    "ax3.imshow(ws_img, cmap=\"tab20\",**plt_settings)\n",
    "ax3.set_title('Watershed Analysis')"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 71,
  "_is_fork": false,
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
